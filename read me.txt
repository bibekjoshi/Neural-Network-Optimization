#Neural-Network-Optimization


The neural network training function is in the file 'nntrain.m'

The file 'data.mat' contains datasets for training the neural network. The inputs are in variable 'X' and output in variable 'y'.

The variable 't_stamp' contains timestamps of data in X any y.

The optimization of hidden layer is implemented in the file 'main.m'.
60% data is used for training and 40% for validation. The division is done randomly.

In order to avoid overfitting, an ensemble of 100 neural networks is trained and only the neural networks with validation performance error less than
the average of ensemble are chosen. The average error of selected neural networks is regarded as the average error for the neural network topology.
The above process is repeated for number of neurons in hidden layer ranging from 1 to 20 and the topology with lowest performance error
is chosen as optimum.

The above process is carried out on both one and two hidden layer topology.

Preliminary results: The performance oscillates with variations in number of neurons for single neural networks. For ensemble with two hidden layers,
the performance vs number of neurons is quite stable with optimum at 10. The results are saved in "png" files in this folder